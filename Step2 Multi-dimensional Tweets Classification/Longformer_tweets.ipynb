{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6f3d8d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark NLP version 3.3.1\n",
      "Apache Spark version: 3.2.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://DESKTOP-03341UF:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Spark NLP</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x20627725130>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import sparknlp\n",
    "spark = sparknlp.start(gpu=True, memory=\"12G\")\n",
    "\n",
    "from sparknlp.base import *\n",
    "from sparknlp.annotator import *\n",
    "from pyspark.ml import Pipeline, Transformer\n",
    "from pyspark.sql.functions import rand, element_at, concat_ws, col, lit, expr\n",
    "from pyspark.ml.feature import VectorAssembler, VectorSizeHint\n",
    "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.util import DefaultParamsReadable, DefaultParamsWritable\n",
    "\n",
    "print(\"Spark NLP version\", sparknlp.version())\n",
    "print(\"Apache Spark version:\", spark.version)\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0bd1653d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Dataset Count: 295652\n",
      "Valid Dataset Count: 126949\n"
     ]
    }
   ],
   "source": [
    "fn = \"data/politifact_tweets_processed.csv\"\n",
    "\n",
    "dataset = spark.read.csv(fn, inferSchema=True, header=True, multiLine=True, escape = '\"').filter(\"text is not NULL\")\n",
    "dataset = dataset.withColumn('text', concat_ws(' | ', col('location'), col('text')))\n",
    "\n",
    "avgs = {col: 'mean' for col in dataset.schema.names if col.endswith('_count')}\n",
    "aggs = [expr(f'percentile({col}, array(0.5))')[0].alias(f'{col}') for col in dataset.schema.names if col.endswith('_count')]\n",
    "meds = dataset.agg(*aggs).toPandas().to_dict(orient = 'list')\n",
    "for column, med in meds.items():\n",
    "    dataset = dataset.fillna(med[0], subset = [column])\n",
    "\n",
    "dataset = dataset.fillna(False, subset=[item[0] for item in dataset.dtypes if item[1].startswith('bool')]) \n",
    " \n",
    "train_dataset, valid_dataset = dataset.randomSplit([0.7, 0.3], seed=42)\n",
    "train_dataset = train_dataset.repartition(32, \"news_id\")\n",
    "valid_dataset = valid_dataset.repartition(32, \"news_id\")\n",
    "print(\"Train Dataset Count: \" + str(train_dataset.count()))\n",
    "print(\"Valid Dataset Count: \" + str(valid_dataset.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "130def3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tweet_id', 'bigint'),\n",
       " ('created_at', 'string'),\n",
       " ('favorite_count', 'int'),\n",
       " ('retweet_count', 'int'),\n",
       " ('user_id', 'bigint'),\n",
       " ('location', 'string'),\n",
       " ('verified', 'boolean'),\n",
       " ('followers_count', 'double'),\n",
       " ('source', 'string'),\n",
       " ('text', 'string'),\n",
       " ('fake', 'double'),\n",
       " ('news_id', 'int')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f82c03d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = LongformerEmbeddings \\\n",
    "      .load(\"models/longformer_base_4096\") \\\n",
    "      .setBatchSize(1024) \\\n",
    "      .setInputCols([\"document\", \"token\"]) \\\n",
    "      .setOutputCol(\"embeddings\") \\\n",
    "      .setCaseSensitive(True) \\\n",
    "      .setMaxSentenceLength(4096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72b56b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DropDim(Transformer, DefaultParamsReadable, DefaultParamsWritable):\n",
    "    def __init__(self):\n",
    "        super(DropDim, self).__init__()\n",
    "\n",
    "    def _transform(self, df):\n",
    "        df = df.withColumn('emb_feature', element_at(df['emb_feature'], 1))\n",
    "        return df\n",
    "\n",
    "document_assembler = DocumentAssembler() \\\n",
    "    .setInputCol(\"text\") \\\n",
    "    .setOutputCol(\"document\") \\\n",
    "    .setIdCol(\"news_id\")\n",
    "    \n",
    "tokenizer = Tokenizer() \\\n",
    "    .setInputCols([\"document\"]) \\\n",
    "    .setOutputCol(\"token\")\n",
    "\n",
    "text_emb = SentenceEmbeddings() \\\n",
    "    .setInputCols([\"document\", \"embeddings\"]) \\\n",
    "    .setOutputCol(\"text_embeddings\") \\\n",
    "    .setPoolingStrategy(\"AVERAGE\")\n",
    "\n",
    "emb_feature = EmbeddingsFinisher() \\\n",
    "   .setInputCols(\"text_embeddings\") \\\n",
    "   .setOutputCols(\"emb_feature\") \\\n",
    "   .setOutputAsVector(True)\n",
    "\n",
    "\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=['emb_feature', 'favorite_count', 'retweet_count', \n",
    "               'verified', 'followers_count', \n",
    "              ], \n",
    "    outputCol=\"features\",\n",
    ")\n",
    "\n",
    "clf = MultilayerPerceptronClassifier(\n",
    "    labelCol='fake', maxIter=30, blockSize=1024, stepSize=1e-4, solver='gd', layers=[772, 128, 2], seed=42)\n",
    "\n",
    "clf_pipeline = Pipeline(stages=[\n",
    "    document_assembler, \n",
    "    tokenizer,\n",
    "    embeddings,\n",
    "    text_emb,\n",
    "    emb_feature,\n",
    "    DropDim(),\n",
    "    assembler,\n",
    "    clf\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "894bdf78",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = clf_pipeline.fit(train_dataset)\n",
    "model.save(f\"models/{os.path.basename(fn).split('.')[0]}-clf-{datetime.now().strftime('%m%d-%H%M')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "69f835af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7311431444854174\n"
     ]
    }
   ],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(labelCol='fake', predictionCol='prediction', metricName='accuracy')\n",
    "\n",
    "\n",
    "train_results = model.transform(train_dataset)\n",
    "train_acc = evaluator.evaluate(train_results)\n",
    "print(train_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5f0cc464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7304114250604573\n"
     ]
    }
   ],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(labelCol='fake', predictionCol='prediction', metricName='accuracy')\n",
    "\n",
    "valid_results = model.transform(valid_dataset)\n",
    "valid_acc = evaluator.evaluate(valid_results)\n",
    "print(valid_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
